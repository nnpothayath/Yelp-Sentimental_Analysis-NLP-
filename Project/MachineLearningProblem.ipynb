{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "import DataOperations\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_Vectorizer():\n",
    "    # Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "    # bag of words tool.\n",
    "    print (\"Creating the bag of words...\\n\")\n",
    "\n",
    "    vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, \n",
    "                                 max_features = 20000) \n",
    "\n",
    "\n",
    "    # fit_transform() does two functions: First, it fits the model\n",
    "    # and learns the vocabulary; second, it transforms our training data\n",
    "    # into feature vectors. The input to fit_transform should be a list of \n",
    "    # strings.\n",
    "    data_features = vectorizer.fit_transform(clean_reviews)\n",
    "\n",
    "    data_features = data_features.toarray()\n",
    "    print(\"Created the bag of words\")\n",
    "\n",
    "    # Take a look at the words in the vocabulary\n",
    "    vocab = vectorizer.get_feature_names()\n",
    "\n",
    "    # # Sum up the counts of each vocabulary word\n",
    "    dist = np.sum(data_features, axis=0)\n",
    "\n",
    "    #The below code obtains the low frequency words\n",
    "    threshold_count=2\n",
    "    low_freq_words=[]\n",
    "    \n",
    "    # #for tag, count in zip(vocab, dist):\n",
    "    low_freq_words=[tag  for tag, count in zip(vocab, dist) if(count<threshold_count)]\n",
    "    \n",
    "    return(data_features)\n",
    "\n",
    "\n",
    "def tfidf_vectorizer(clean_reviews): \n",
    "    print(\"Preparing to vectorize the text using tf-idf\")\n",
    "    # This vectorizer breaks text into single words and bi-grams and then calculates the TF-IDF representation\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "    # the 'fit' builds up the vocabulary from all the reviews while the 'transform' step turns each indivdual text into\n",
    "    # a matrix of numbers.\n",
    "    vectors = vectorizer.fit_transform(clean_reviews)\n",
    "    print(\"Completed tf-idf vectorization of text data\")\n",
    "    return(vectors)\n",
    "\n",
    "\n",
    "def gaussian_Naive_Bayes(vectors, stars):    \n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    clf = GaussianNB()\n",
    "    print(\"Running Gaussian Naive Bayes\")\n",
    "    clf.fit(vectors.toarray(), stars)\n",
    "    scores = cross_val_score(clf, vectors.toarray(), stars, cv=2)\n",
    "    #print(\"Getting Scores\")\n",
    "    #print(scores)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "def linear_SVM(vectors, stars):\n",
    "    from sklearn.svm import LinearSVC\n",
    "    classifier = LinearSVC()\n",
    "    print(\"Running Linear SVM Classifier\")\n",
    "    classifier.fit(vectors.toarray(), stars)\n",
    "    scores = cross_val_score(classifier, vectors.toarray(), stars, cv=2)\n",
    "    #print(\"Getting Scores\")\n",
    "    #print(scores)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "def random_Forest_Classifier(vectors, stars):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    classifierRF = RandomForestClassifier()\n",
    "    print(\"Running Random Forest Classifier\")\n",
    "    classifierRF.fit(vectors.toarray(), stars)\n",
    "    scores = cross_val_score(classifierRF, vectors.toarray(), stars, cv=2)\n",
    "    #print(\"Getting Scores\")\n",
    "    #print(scores)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "def tune_linear_svm(vectors, stars):\n",
    "    from sklearn.grid_search import GridSearchCV\n",
    "    from sklearn.svm import LinearSVC\n",
    "    print(\"Obtaining best hyper-parameters for Linear SVM Classifier\")\n",
    "    grid={\"C\": [0.05,0.5,1,1.5,2,5,10], \"loss\": [\"hinge\", \"squared_hinge\"], \"class_weight\": [None,\"balanced\"]}\n",
    "\n",
    "    train_X = vectors.toarray()\n",
    "    train_y = stars\n",
    "\n",
    "    clf = GridSearchCV(LinearSVC(), grid, cv=2).fit(train_X, train_y)\n",
    "\n",
    "    print(clf.best_params_)\n",
    "    print(str(clf.best_score_))\n",
    "    \n",
    "    return clf\n",
    "\n",
    "def logistic_Regression(vectors, stars):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    model = LogisticRegression() \n",
    "    model.fit(vectors.toarray(), stars)\n",
    "    scores = cross_val_score(model, vectors.toarray(), stars, cv=2)\n",
    "    #print(\"Getting Scores\")\n",
    "    #print(scores)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allOperations(userID):\n",
    "    reviews = DataOperations.readData()\n",
    "    #Getting all reviews for the user with most reviews\n",
    "    texts = [review['text'] for review in reviews if review['user_id'] == str(userID)]\n",
    "    #Getting all ratings for the user with most reviews\n",
    "    stars = [review['stars'] for review in reviews if review['user_id'] == str(userID)]\n",
    "    clean_reviews = []\n",
    "    clean_reviews = DataOperations.clean_Reviews(texts)\n",
    "    vectors = tfidf_vectorizer(clean_reviews)\n",
    "    gaussian_Naive_Bayes(vectors, stars)\n",
    "    linear_SVM(vectors, stars)\n",
    "    random_Forest_Classifier(vectors, stars)\n",
    "    tune_linear_svm(vectors, stars)\n",
    "    logistic_Regression(vectors, stars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
